chip multiprocessor code scheduling data placement embedded systems loop scheduling performance optimization embedded systems have three common principles real-time performance low power consumption and low price limited hardware embedded computers use chip multiprocessors cmps to meet these expectations however one of the major problems is lack of efficient software support for cmps in particular automated code parallelizers are neededthe aim of this study is to explore various ways to increase performance as well as reducing resource usage and energy consumption for embedded systems we use code restructuring loop scheduling data transformation code and data placement and scratch-pad memory spm management as our tools in different embedded system scenarios the majority of our work is focused on loop scheduling main contributions of our work arewe propose a memory saving strategy that exploits the value locality in array data by storing arrays in a compressed form based on the compressed forms of the input arrays our approach automatically determines the compressed forms of the output arrays and also automatically restructures the codewe propose and evaluate a compiler-directed code scheduling scheme which considers both parallelism and data locality it analyzes the code using a locality parallelism graph representation and assigns the nodes of this graph to processorswe also introduce an integer linear programming based formulation of the scheduling problemwe propose a compiler-based spm conscious loop scheduling strategy for arrayloop based embedded applications the method is to distribute loop iterations across parallel processors in an spm-conscious manner the compiler identifies potential spm hits and misses and distributes loop iterations such that the processors have close execution timeswe present an spm management technique using markov chain based data accesswe propose a compiler directed integrated code and data placement scheme for 2-d mesh based cmp architectures using a code-data affinity graph cdag to represent the relationship between loop iterations and array data it assigns the sets of loop iterations to processing cores and sets of data blocks to on-chip memories we present a memory bank aware dynamic loop scheduling scheme for array intensive applicationsthe goal is to minimize the number of memory banks needed for executing the group of loop iterations