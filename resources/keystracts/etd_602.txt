 the kullback-leibler kl divergence is one of the most fundamental metrics in information theory and statistics and provides various operational interpretations in the context of mathematical communication theory and statistical hypothesis testing the kl divergence for discrete distributions has the desired continuity property which leads to some fundamental results in universal hypothesis testing with continuous observations however the kl divergence is only lower semi-continuous difficulties arise when tackling universal hypothesis testing with continuous observations due to the lack of continuity in kl divergencethis dissertation proposes a robust version of the kl divergence for continuous alphabets specifically the kl divergence defined from a distribution to the levy ball centered at the other distribution is found to be continuous this robust version of the kl divergence allows one to generalize the result in universal hypothesis testing for discrete alphabets to that for continuous observations the optimal decision rule is developed whose robust property is provably established for universal hypothesis testinganother application of the robust kl divergence is in deviation detection the problem of detecting deviation from a nominal distribution using a sequence of independent and identically distributed observations an asymptotically -optimal detector is then developed for deviation detection where the levy metric becomes a very natural distance measure for deviation from the nominal distributionlastly the dissertation considers the following variation of a distributed detection problem a sensor may overhear other sensors' transmissions and thus may choose to refine its output in the hope of achieving a better detection performance while this is shown to be possible for the fixed sample size test asymptotically in the number of samples there is no performance gain as measured by the kl divergence achievable at the fusion center provided that the observations are conditionally independent for conditionally dependent observations however asymptotic detection performance may indeed be improved when overhearing is utilized