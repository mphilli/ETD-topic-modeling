dirac delta ordinary least squares production skewness stochastic frontier this dissertation consists of three essays on stochastic frontier models in characterizing inefficiency for a cross section of firms in essays one and three and a set of firms overtime in essay two the first essay looks at stationary points for several models used in stochastic frontier analysis the second essay extends the multivariate probability statements of horrace 2005 to calculate the probability that a firm is any particular efficiency rank these rank probabilities are used to calculate expected efficiency ranks for each firm the third and final essay adds spatial correlation to the production function of each firm and generalizes the horrace 2005 probability statementsthe skew of ordinary least squares ols residuals of the composed error is expected to be negative and positive for a production function and a cost function respectively however because of sampling errors in empirical applications modelers may get a positive skew for a production function and this has serious implication for maximum likelihood estimates mles  this is called the wrong skew problem waldman 1982 shows that for the normal-half normal model if the wrong skew occurs then 1 mles reduce to ols 2 this solution is stable and 3 there is a relationship between the skew of ols residuals and the mle of the pretruncated variance of inefficiency in the literature two solutions are provided when the wrong skew occurs 1 find a new random sample however this might be too costly and 2 respecify the distribution of inefficiencythe first essay generalizes part 1 of waldman 1982 result using the theory of the dirac measure dirac 1930 this essay shows that if the inefficiency distribution converges to a dirac delta function when the pretruncated variance of the inefficiency distribution goes to zero the likelihood of the composed error will converge to a likelihood based solely on the noise distribution in particular this essay shows that if the dirac delta function is centered at zero then the maximum likelihood estimator equals the ordinary least squares estimator in the limit the parameters of the inefficiency distribution are not identified in the limit stability of the maximum likelihood estimator and the wrong skew results are derived or simulated for common parametric assumptions on the inefficiency distribution this essay shows that the full suite of waldman 1982 result holds for the normal-doubly truncated normal and the normal-truncated normal models when the pretruncated mean is non-positive simulation results show that if the wrong skew occurs the mles for the normal-doubly truncated normal when the upper bound b b2 where  is the pretruncated mean the normal-truncated normal and the normal-exponential models reduce to ols  a cost function with the wrong skew of ols residuals is estimated using the greenes airline data and the results show that the normal-truncated normal and the normal-exponential models reduce to ols overall the results reveal that respecifying using the traditional assumptions for the inefficiency distribution is unnecessary if the wrong skew of ols residuals occursempirical applications of frontier analysis are abundant ranging from the airline industry to the farming industry see battese and coelli 1995 1992 druska and horrace 2004 and almanidis qian and sickles 2014 in empirical applications a modeler typically proceeds by estimating a cobb-douglas production function or a cost function for a set of firms for a production function output is proxy by the total sales deflated by a price index inputs include all the factors of production such as land labor and capital the first step is to estimate ols since it provides consistent estimates for all the parameters except the intercept or corrected ordinary least squares cols which is ols corrected for the biased intercept the next step is to examine the skew the third central moment of ols residuals before proceeding to mle which is more efficient than ols the skew has important information so it is used as a guideline for empiricists as to how to proceed in applications if the skew has the correct sign negative for a production function empiricists proceed to mle if the skew has the wrong sign positive for a production function empiricists respecify the distribution for inefficiency this first essay shows that in empirical applications if a modeler encounters the wrong skew respecifying using the normal-truncated or the normal-exponential model is a futile procedure since these models do not provide any new resultsthe second essay extends the multivariate probability statements of horrace 2005 to calculate the conditional probability that a firm is any particular efficiency rank in a sample conditional expected efficiency ranks are constructed for each firm in particular it can be determined which firm in the sample is the best 2nd best 2nd  worst and worst in the population of firms firm level conditional expected efficiency ranks are more informative about the degree of uncertainty in regards to ranking when compared to the traditional ranked efficiency point estimates a monte carlo study reveals that under low skew the expected efficiency rank provides inferential insights which the traditional conditional mean function would not uncoverthe mles of the parameters under the assumption that there are no estimation errors or parameters uncertainty post estimation are substituted into the conditional mean function the conditional mean function is the mean of inefficiency conditioned on the composed error and is used to produce estimates for inefficiencies for each firm in the sample see jondrow lovell materov and schmidt 1982 the probability statements utilize both the first and the second moments which provide a more accurate description of the distribution inefficiency in empirical applications to determine which firm is any efficiency rank the modeler substitutes mles into the probability statements inefficiency conditioned on the composed error and simulates the probabilities the firm with the largest probability is interpreted as the best firm in the sample and the firm with the smallest probability is interpreted as the worst firm in the sample thereafter the modeler uses these conditional probabilities to compute the expected efficiency rank such that the firm with the largest value of the expected efficiency rank is deemed the least efficient or ranked the worst and the firm with the smallest value is ranked as the most efficient or the best firm in the samplethe third essay generalizes the horrace 2005 probability statements to account for spatial correlation in the unobservable for a cross section of firms this essay relaxes the assumption of independence on the noise or signal or both noise and signal distributions this essay makes two assumptions on the inefficiency signal distribution 1 inefficiency is assumed to be truncated from a normal distribution prior to the addition of spatial correlation and 2 inefficiency is drawn from a normal distribution and then truncated the addition of spatial correlation to the production function results in the likelihood being intractable as the number of integrals increases with the sample size this essay uses sequential conditioning by spanos 1986 1999 to factor the joint distribution into the product of a marginal and univariate conditional distributions to compute the probability of the least and most efficient firm unlike horrace 2005 if inefficiency is assumed to be spatially correlated the conditional distribution of inefficiency conditioned on the composed error is not needed to compute the probabilities the mles are substituted directly into the probability statements this is because spatial dependence induces heteroskedascity that results in variation across the firms overall this essay provides some insights to empiricists in making inference when the assumption of independence on the noise and inefficiency distributions is relaxedthe presence of spatial correlation in the errors shifts the production function outward or inward the composed error is not random because firms are locating in specific areas due to easier access to specialized workers which reduces the search cost of matching workers to the appropriate firms furthermore firms will locate in places where there are more favorable demand conditions similar cultural practices bureaucratic organization work ethics and economic activities having better access to inputs will affect the productivity of a given firm however these activities are not observed by the econometrician these activities affect efficiency and need to be accounted for empirically to provide a better characterization of inefficiency the spatial correlation is captured using a prespecified weighted matrix there are several ways of determining the weights for instance a modeler could employ contiguity weights or use an inverse distance function the inverse distance function means that firms further away from each other will impact each other less  these weights are typically known prior to estimation the weighted matrix is added to the production function before estimation begins post estimation mles or cols are substituted into the probability statements developed in horrace 2005 in which the modeler will be able to compute the probability that firm i is the least or most efficient firm in the sample