$TITLE:
Modeling neural networks via linguistically interpretable fuzzy inference systems

$DEPARTMENT:
Electrical Engineering and Computer Science

$KEYWORDS:
Neural networks, Interpretable, Fuzzy inference

$ABSTRACT:
This dissertation proposes a fuzzy-arithmetic-based method for extracting fuzzy inference systems from trained, three-layer (input, hidden and output), feedforward, artificial neural networks. While the transfer function of the network's hidden layer may be non-linear, the output layer contains only a single neuron whose transfer function is linear. (Our method is easily extended to networks with multiple, linear output layer neurons.) The intent of our approach is to provide linguistic interpretation with respect to the functioning of the modeled neural network. While an infinite number of fuzzy inference systems accurately model the network's input/output mapping, by decomposing the task into optimally approximating, to arbitrary accuracy, the behavior of the individual neurons (optimal in the least squares sense), the network's internal behavior is also captured. Modeling proceeds as follows: (1) for each neuron, a fuzzy inference system is generated in a deterministic, closed-formed fashion; (2) these systems are combined into a single fuzzy inference system whose output is equivalent to the sum of the weighted outputs of the individual systems; (3) genetic algorithms are then applied to tune the membership functions; and (4) a deterministic technique is employed to reduce the number of rules and shorten the antecedents of any remaining rules. In the development of our method, several novel concepts are introduced, including: (1) a defuzzification approach that respects the additivity of fuzzy sets; (2) intermediate representations of fuzzy inference systems such as enhanced multiple input/single output systems, single input/single output fuzzy decision trees (SISO FDTs), and networks of SISO FDTs; (3) a closed-formed solution for optimally modeling neurons; and (4) a genetic algorithm crossover operator designed to avoid premature convergence.