$TITLE:
Knowing Better, Reasoning Together

$DEPARTMENT:
Philosophy

$KEYWORDS:


$ABSTRACT:
We take ourselves to have some knowledge about what’s right and wrong to do. But how easy is this knowledge to get? In the first two chapters of this dissertation I argue for the novel conclusion that it is harder to have moral knowledge than non-moral knowledge due to the fact that moral beliefs have more practically at stake. More specifically, in chapter 1 I argue that moral beliefs are subject to a higher epistemic standard than non-moral beliefs. Roughly, epistemic standards mark how good of an epistemic position an agent needs to be in in order for her beliefs to receive epistemic credit like knowledge. The higher epistemic standard of moral beliefs offers the only unified explanation to date of long-standing puzzling asymmetries between moral and non-moral epistemology, like how moral testimony, unlike non-moral testimony, is problematic and moral expertise, unlike non-moral expertise, is non-existent.Even so, one may wonder why moral beliefs have such a higher epistemic standard. In chapter 2 I argue that the best account of what fixes the higher epistemic standard for moral beliefs is a practical-stakes account wherein the practical upshots of holding a belief affect how demanding the standard is. Importantly, my account differs from traditional practical-stakes accounts of epistemic standards. First, it locates features of morality as a subject matter, like being subject to the reactive attitudes and the way that moral beliefs typically motivate whereas non-moral beliefs don’t, as that which functions to raise the standard. Second, the stakes that are relevant outrun those stemming from the interests of the individual person whose belief is under assessment, and include the practical interests of other agents. This last feature makes the picture of moral knowledge I offer essentially social, as whether or not one has moral knowledge depends in part on the interests of others. In the end, the view I offer in these chapters presents a perhaps surprising picture of moral epistemology as systematically different from non-moral epistemology.In chapter 3 I investigate in more detail the social basis of moral knowledge by considering one particular view of the nature of moral facts, constructivism. According to this view, moral facts are determined by what would be the result of a hypothetical choice procedure amongst an idealized group of agents. Here I argue that the best moral epistemology on offer for the constructivist requires an agent to be able to respond to the objections that relevant others would have to the content of one’s belief in order for that belief to count as knowledge. In this way, moral knowledge for constructivists requires the ability to reason together with others about morality.After considering social constraints on moral knowledge, in chapter 4 I turn to consider whether normativity may likewise have a social basis. Here, I consider social-based views of normativity wherein an agent’s reasons for action are determined by the social institutions, practices, and relations (IPRs) she takes part in. I argue that existing views have trouble ensuring that certain intuitively bad social practices--namely, oppressive ones--aren’t a source of reasons. In light of this, I develop a novel positive view, Looping Social Constructivism, according to which an agent’s reasons are a function of the IPRs she takes part in, after they are idealized. Specifically, they are idealized such that each role in the IPR has the same ability to determine how rights, responsibilities, and power are distributed across the IPR. Looping Social Constructivism is able to avoid issues of oppressive IPRs given its unique use of idealization on the social level: instead of idealizing the individual agents taking part in an IPR, we idealize structural features of the IPR itself.